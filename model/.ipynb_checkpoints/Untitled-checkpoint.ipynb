{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import MovieDataset, PadCollate\n",
    "from torch.utils.data import DataLoader\n",
    "from model import MoviePredict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dataset = MovieDataset('../train_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(movie_dataset, collate_fn=PadCollate(), batch_size=3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3440, 1566,    1,    1, 5029,    1,    1, 1136, 8182, 1025, 8183,    1,\n",
       "             1,    1,    1, 7810,    1,    1,    1,    1,    1, 6793, 8184],\n",
       "         [1191, 1163, 6900, 8298, 2127,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   1,    1,    1,    1, 2976,    1,    1,    1,    1,    1,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " tensor([[  1],\n",
       "         [917],\n",
       "         [  1]]),\n",
       " tensor([[17,  0, 14],\n",
       "         [ 4,  0,  0],\n",
       "         [12,  0,  0]]),\n",
       " tensor([[18],\n",
       "         [ 1],\n",
       "         [ 1]]),\n",
       " tensor([[15437, 12306,   245,    24,   154,     4,  4209,     6,  4570, 11749,\n",
       "          18166,    62,  2811,    24,   347, 16205,   764,    28,   947,     8,\n",
       "            154,     5,  2874,    69,  2969,     5,   409,   426,   171,   266,\n",
       "           1709, 21149,     3,    70,   575,   705,     5,  3417,   102,   325,\n",
       "             23, 17006,   526,     8,  1144,  9326,    18,    47,   488,   617,\n",
       "              5,  4010,     3,    52,    61,    51,     8,   917,   562,   692,\n",
       "           5412,   256,     7, 30392,    33,  6195,   245,  5087, 18450,    42,\n",
       "              7,   154,     4,   396,  1085,    19,  9286, 11011,    21,    11,\n",
       "           6587,  1183,     8,   171,  1892,   456, 14600,   407,   917,  4870,\n",
       "          11184,    72,  5303,     3,   417,     4,  1139,  2363,   943,   171,\n",
       "            266,     3,    57,   339,   223,  6471,    10,  3944, 12306,   245,\n",
       "              5,  4810,  2320, 10538,    13,   154,     4,  4209,     6,  4570,\n",
       "          17583,  6243,  6903,     4,    19,  9286, 11011,    21,    16, 11183,\n",
       "             89,    62,   100,     3,   682,   180,    10,   215,   311,     8,\n",
       "            223,  1981,    12,   634,    14, 30105,     5,  2376,  1221,  1725,\n",
       "            325,     4,   180,    10,   134,  6732,    29,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 3461,   644, 23513,    88,  1302,  1156,  7322,   728,  9960,     3,\n",
       "          23250,    13, 26512,   728,    54,   729,  4876,  1541,   728,   196,\n",
       "            333,  1606,   242,  3588,    20,    93, 13563,     8,  3296, 26530,\n",
       "             13,  7818,  4641,    17, 14839,    15,    10,   109,   962,  1317,\n",
       "           2836, 11516,    12,  2380,    96,     9, 31917,     5,  2341,  8378,\n",
       "            225, 31893,  1616,    26,    53,  1461,   176,   788,   104,  6166,\n",
       "             22,     3,   122,    61,    51,   224,  4641,   227,  1813,  8835,\n",
       "             11, 13954,  6048,     8,    70,   194,  3735,   102,   545, 12667,\n",
       "           1199,  4548,   249,    73,   833, 12072, 19729,     4,  2849,   542,\n",
       "            490, 13689,    17, 14819,   408,   659,     6, 18924,   107,  1276,\n",
       "            123,   301, 15052,  4641,     5,  3643,   749, 17658,    33,   605,\n",
       "           2084,  9216,  4566, 13689,     7,  1943,   752,  2865,    12,  1317,\n",
       "              5,     9, 31917,    41,  4615,   130,   550,  4641,     4,  5519,\n",
       "              1,     5, 11990,  1853,  7576,     3,   688, 13689,     7,  4641,\n",
       "              4, 22421,    67, 10854,  9952,    14,  7547,     4, 17651,    12,\n",
       "           1714,    50,    56,  5425,    12,  7419,  4038,   345,    11, 14724,\n",
       "            126,    81,    34,     3,  8630,   303,   930,    40,  1636,     5,\n",
       "          19963,    73, 14562,    13,  1279,     6,  9843,  7547,     5,  2061,\n",
       "            609,  2083,    54,   199, 14843,   297, 13689,    11, 15256, 16106,\n",
       "           1636,     5,  3714,  1653, 10111,    42,     3,    95,     8,  1636,\n",
       "              5,  5941,   278,   764, 10945,  5859, 13689,     7,   194,  2643,\n",
       "             84,  1358,     4,  1290,    12,   235,  7547,    13,  7598,  1243,\n",
       "              5,  2796,    31,    56,     8,   770,     5,   406,  1636,    10,\n",
       "          21825,    54,   138,   652,  9697,    34,     3,  3007,  2165, 19640,\n",
       "           1636,     4,  3505, 11724,    35,  5691,  3266,   341,    26,  1005,\n",
       "              3,  2417,    54,  7417,    10,   341,    26,  1005,     6, 30300,\n",
       "              7,  1537,  1405,  6474,  8223,     7,  1385, 23014, 26670,  6199,\n",
       "           1576,  1180,    11,    34,     3,  5179, 13689,    18,  4641,    10,\n",
       "           1394,    28,   173,   542,    95,    13,    56,     8,    27,  1608,\n",
       "             26,  3853,   554,   130,  4209,     6,  2393,   172,  1537, 19852],\n",
       "         [  114,    89,  6416,   306,   239, 31965, 15590,    59,  8456,     8,\n",
       "           4976, 17030,  1994, 25808,  4986,     3,     9,     1,    71,   162,\n",
       "            107,   405,   954,  1589,    87,  7963,     5,  2247,   201,   155,\n",
       "           1263,  1909,     4,  5038,  3130,   168,    24,   145,  2396,    11,\n",
       "           3098,   732,  4067,  7949, 14921,     3, 14803,   757,    11,     6,\n",
       "           7658,    73,   127,     4,  8680,     6,  5417,    37,   256,    26,\n",
       "          23833,   221,    53, 12016,  2737,    29,   194,     8,  1385,     4,\n",
       "          12820,    92,     3,  4880,    14,    41,   540,  2104,  1443,  5641,\n",
       "             10, 14498,   307,     5,   393,  6314,    16,  2462,     8,   457,\n",
       "            111,  1644, 10615,   797, 31928,    13,    11,   569, 24752,   468,\n",
       "           1349,   966,  4623,  3627,     3,  2560,    31,  4676,    12, 17214,\n",
       "          12758,    13, 12978,     8,  8405, 11073,   213,     3,  2339,   511,\n",
       "          12678,   293, 23365,     4,   865,     1,    20, 18989,    11,     7,\n",
       "            941, 15619,   132,   157,   811,     3,   122,    71,  8665,   104,\n",
       "           3327,  8573, 31975,    22,     3,   185,  7953,  5023,   328,   390,\n",
       "             53,  5641,     4,  1347,    24,   715,     8, 14921,     4,   851,\n",
       "           5984, 22092,     3,  6526,    86,  1164,     8, 27705,    86,   173,\n",
       "           6428,    14,  5342, 12680, 14921,    10,  2013,     4,  3311,   542,\n",
       "           3975,  1132,    27,   440,     5,  8223,   378,    29,   119,     8,\n",
       "          14921,  2212, 13361,     4,   523,    11,   129, 26523,    59,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " tensor([[0.7850],\n",
       "         [0.7790],\n",
       "         [0.7900]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../meta_data.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "voca_num = len(data['vocab'])\n",
    "actor_num = len(data['actors'])\n",
    "director_num = len(data['directors'])\n",
    "category_num = len(data['categories'])\n",
    "country_num = len(data['countries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoviePredict(voca_num, actor_num, director_num, category_num, country_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = next(iter(dataloader))[:-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embs = model.word_embedding(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 300, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3-dimensional input for 3-dimensional weight 128 256 1, but got 4-dimensional input of size [3, 1, 300, 256] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b038aa208b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_conv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-b038aa208b32>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_conv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 202\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3-dimensional input for 3-dimensional weight 128 256 1, but got 4-dimensional input of size [3, 1, 300, 256] instead"
     ]
    }
   ],
   "source": [
    "[conv(word_embs.unsqueeze(1)) for conv in model.sentence_conv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
